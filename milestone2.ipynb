{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load a subset of Quotations from politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.data_wrangling.load_data import load_political_quotes\n",
    "quotes = []\n",
    "for batch in load_political_quotes(country=['United States of America'], political_alignment=['right-wing'],\n",
    "                                   year=[2020], chunksize=20000):\n",
    "    quotes.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quotation</th>\n",
       "      <th>speaker</th>\n",
       "      <th>qid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quoteID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-16-000088</th>\n",
       "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
       "      <td>Sue Myrick</td>\n",
       "      <td>Q367796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19-000276</th>\n",
       "      <td>[ These ] actions will allow households who ha...</td>\n",
       "      <td>Ben Carson</td>\n",
       "      <td>Q816459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20-000982</th>\n",
       "      <td>a host of other protections</td>\n",
       "      <td>Debbie Lesko</td>\n",
       "      <td>Q16731415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-19-002801</th>\n",
       "      <td>All immigration to the US should be halted due...</td>\n",
       "      <td>Laura Ingraham</td>\n",
       "      <td>Q266863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24-004650</th>\n",
       "      <td>And they are working towards delivering their ...</td>\n",
       "      <td>Mike Pompeo</td>\n",
       "      <td>Q473239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-20-084503</th>\n",
       "      <td>who is out to discover if a mythic superhero, ...</td>\n",
       "      <td>Sylvester Stallone</td>\n",
       "      <td>Q40026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-04-047023</th>\n",
       "      <td>Worshippers. They were praying and this maniac...</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Q22686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-28-113424</th>\n",
       "      <td>yep, it was true, every word of it, so get ove...</td>\n",
       "      <td>Mick Mulvaney</td>\n",
       "      <td>Q1235731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07-071722</th>\n",
       "      <td>You can come to a polling place and do it safe...</td>\n",
       "      <td>Robin Vos</td>\n",
       "      <td>Q7352841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-24-093541</th>\n",
       "      <td>You can't get social distance in a submarine a...</td>\n",
       "      <td>Mark Esper</td>\n",
       "      <td>Q33190271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234253 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           quotation  \\\n",
       "quoteID                                                                \n",
       "2020-01-16-000088  [ Department of Homeland Security ] was livid ...   \n",
       "2020-03-19-000276  [ These ] actions will allow households who ha...   \n",
       "2020-01-20-000982                        a host of other protections   \n",
       "2020-03-19-002801  All immigration to the US should be halted due...   \n",
       "2020-03-24-004650  And they are working towards delivering their ...   \n",
       "...                                                              ...   \n",
       "2020-01-20-084503  who is out to discover if a mythic superhero, ...   \n",
       "2020-01-04-047023  Worshippers. They were praying and this maniac...   \n",
       "2020-01-28-113424  yep, it was true, every word of it, so get ove...   \n",
       "2020-04-07-071722  You can come to a polling place and do it safe...   \n",
       "2020-03-24-093541  You can't get social distance in a submarine a...   \n",
       "\n",
       "                              speaker        qid  \n",
       "quoteID                                           \n",
       "2020-01-16-000088          Sue Myrick    Q367796  \n",
       "2020-03-19-000276          Ben Carson    Q816459  \n",
       "2020-01-20-000982        Debbie Lesko  Q16731415  \n",
       "2020-03-19-002801      Laura Ingraham    Q266863  \n",
       "2020-03-24-004650         Mike Pompeo    Q473239  \n",
       "...                               ...        ...  \n",
       "2020-01-20-084503  Sylvester Stallone     Q40026  \n",
       "2020-01-04-047023        Donald Trump     Q22686  \n",
       "2020-01-28-113424       Mick Mulvaney   Q1235731  \n",
       "2020-04-07-071722           Robin Vos   Q7352841  \n",
       "2020-03-24-093541          Mark Esper  Q33190271  \n",
       "\n",
       "[234253 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politician_quotes = pd.concat(quotes, axis=0, ignore_index=False)\n",
    "politician_quotes = politician_quotes[['quotation', 'speaker', 'qid']]\n",
    "politician_quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using Top2Vec for topic extraction\n",
    "Our basic idea for extracting topics from the quotes was as followed:\n",
    "1) using a pretrained embedding to embed the quotes into a semantic space. Our idea was to use word2vec for each word and average over each quote.\n",
    "2) probably reduce the dimensonality of the embedding. If the embedding has too many dimensions, this could reduce the quality of the clustering result, as well as be too computationally expensive.\n",
    "3) cluster the lower dimensional embedding and use clusters as topics\n",
    "\n",
    "We found a already existing tool called [Top2Vec](https://github.com/ddangelov/Top2Vec) which does basically this and offers some convinience features.\n",
    "Main differences are:\n",
    "- the usage of a doc2vec model for the embedding. It is trained on the input data, we will probably replace it by another embedding.\n",
    "- reassigning \"noise\" documents/quotes to closest cluster\n",
    "\n",
    "We descided to use this instead of coding the pipeline ourself, since its already there and uses some indexed datastructure to speed it up and already allows to save the entire trained model. We will probably adapt this implementation to our needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage of top2vec on quotedata from 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from top2vec import Top2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Top2Vec\n",
    "Here we configure Top2Vec and prepare the data. Top2Vec wants the documents and the ids as a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_for_top2vec = politician_quotes['quotation'].tolist()\n",
    "ids_for_top2vec  = politician_quotes.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we configure the dimensionality reduction(UMAP) and the clustering(HDBSCAN) steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_args = {'n_neighbors': 15,\n",
    "             'n_components': 15,\n",
    "             'metric': 'cosine'}\n",
    "hdbscan_args = {'min_cluster_size': 5,\n",
    "                'metric': 'euclidean',\n",
    "                'cluster_selection_method': 'eom'#, 'core_dist_n_jobs': 1 if pickable error\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speed option chooses a preconfiguration of for doc2vec. Here we used the quickest preset. But this we could also  modify later in the top2vec code manually to get optimal results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the pipeline(Doc2Vec, UMAP, HDBSCAN, AssignToTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 22:37:01,748 - top2vec - INFO - Pre-processing documents for training\n",
      "2021-11-12 22:37:15,516 - top2vec - INFO - Creating joint document/word embedding\n"
     ]
    }
   ],
   "source": [
    "model = Top2Vec(documents_for_top2vec, document_ids=ids_for_top2vec, speed='fast-learn',\n",
    "                umap_args=umap_args, hdbscan_args=hdbscan_args, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and save the model for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"2020-doc2vec-fast2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A quick look at the results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many topics did we find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_num_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(model.get_num_topics()):\n",
    "    model.generate_topic_wordcloud(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Sentiment analysis with TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know if the quotes have a positive or a negative intention. In the following section a sentiment analysis approach was done with TextBlob. TextBlob is a python library for Natural Language Processing (NLP).It uses Natural Language ToolKit (NLTK) to achieve its tasks. It can be used for complex analysis on textual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract some quotes from a single cluster topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotations, quotation_scores, quotation_ids = model.search_documents_by_topic(topic_num=0, num_docs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example data frame, must be replaced by dataframe of citations for one topic (filtering)\n",
    "df = politician_quotes.loc[quotation_ids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sentiment_analysis import get_subjectivity, get_polarity, get_sentiment\n",
    "# add to DataFrame\n",
    "df['polarity'] = df['quotation'].apply(get_polarity)\n",
    "df['analysis'] = df['polarity'].apply(get_sentiment)\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count pos, neg and neutral citations\n",
    "tb_counts = df.analysis.value_counts()\n",
    "print(tb_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title(\"Polarity\", color = 'g')\n",
    "plt.pie(tb_counts.values, labels = tb_counts.index,  autopct='%1.1f%%')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Distribution of polarity values')\n",
    "plt.hist(df['Polarity'])\n",
    "plt.xlabel('Polarity in the range of -1 = negative, to 1 = positive')\n",
    "plt.ylabel('Occurence of the value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scripts.word2vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Download file if not present\n",
    "df = pd.read_csv('quotes-2020-politicians.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Extend dataframe with the quotes vectors\n",
    "\n",
    "w2v.extend_dataframe(df, 'quotation', 'quotation_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
